---
title: "Untitled"
output:
  html_document: default
  pdf_document: default
date: "2024-11-10"
---

# Module 7

-   Data points (x,y) are naturally paired samples as x and y come from the same observation

## Pearson Correlation Coefficient

### Proc corr - options

will produce matrix of pearson corr coef's with pvalue directly beneath it, all var variables will be the rows and columns so the main diagonal will be all 1's.

```{r,eval=FALSE}
PROC CORR DATA= fitness NOSIMPLE;  #change to PROC CORR DATA= fitness NOSIMPLE; to only get corr coef and p-value or replace "NOSIMPLE" with RANK
    VAR Oxygen_Consumption Runtime; #2x2 matrix produced by only var variables inputted
RUN;
```

### Proc corr - correlation coeffient matrix

will produce matrix of cooraltion coeficients, rows = with, columns = vards, with output in order of rank corr coef largest to least

```{r,eval=FALSE}
PROC CORR DATA= fitness RANK;
  VAR Runtime Age Weight Run_Pulse Rest_Pulse Maximum_Pulse Performance; # 1x7 corr coef matrix will also print simple statistics
  WITH Oxygen_Consumption;
RUN;

PROC CORR DATA= fitness NOSIMPLE;
  VAR Runtime Age Weight Run_Pulse Rest_Pulse Maximum_Pulse Performance; # 7x7 corr coef matrix, no statistics, only corr coef and p-values 
RUN;
```

### Pearson product-moment and Spearman rank-order correlation

```{r,eval=FALSE}
DATA spearcc;
  INPUT X Y XRank YRank;
  DATALINES;
   1  1  1 1
   3  2  2 2
   7  3  3 3
   9  6  4 4
  11  8  5 5
;
RUN;
PROC CORR DATA=spearcc 
PEARSON /*Requests Pearson product-moment correlation  */
SPEARMAN /*Requests Spearman rank-order correlation */    NOSIMPLE 
NOPROB /*Suppresses p-values */; 
RUN;
```

### partial cooralation option

```{r,eval=FALSE}
PROC CORR DATA=fitness;
  VAR Oxygen_Consumption Runtime Run_Pulse Rest_Pulse Maximum_Pulse Age Weight; 
  PARTIAL Performance; #*The PARTIAL statement lists variables to use in the calculation of partial correlation statistics.*/
RUN;        
```

output: the p-values are testing H0: population corr coef = 0

```{r,eval=FALSE}
Pearson Correlation Coefficients, N = 31
                        Prob > |r| under H0: Rho=0
Oxygen_Consumption   Performance        Runtime      Rest_Pulse
                         0.86377       -0.86219        -0.39935

         PVALUE          <.0001         <.0001          0.0260

Oxygen_Consumption     Run_Pulse          Age     Maximum_Pulse
                        -0.39808       -0.31162        -0.23677
        PVALUE           0.0266         0.0879          0.1997

Oxygen_Consumption        Weight
                        -0.16289
            PVALUE       0.3813

```

```{r,eval=FALSE}
± 1.00 	Perfect Correlation
± 0.80 	Strong Correlation
± 0.50 	Moderate Correlation
± 0.20 	Weak Correlation
± 0.00 	No Correlation
```

### R-square - aka coef of determination

is just the (pearson correlation coef)\^2 variables corresponding to signifigant R\^2 p-values have a significant linear correlation between each other.


## Regression 

### conditions of regression analysis validity

assumptions for regression model 
```{r,eval=FALSE}
The errors have a mean of 0 at each value of the independent variable.
The errors have the same variance at each value of the independent variable.
The errors are independent.
The errors are normally distributed (for confidence intervals and tests).
```

Plots to verify assumptions:
Residuals vs. Predicted (predicted responce variable by the model)
Residuals vs. (Observed Values of the Independent Variable, used to produce model)
Studentized Residuals vs. (Observed Values of the Independent Variable) (OBS)
Residual by QQ plot

```{r,eval=FALSE}
GOPTIONS RESET=ALL;
PROC REG DATA= fitness;
MODEL Oxygen_Consumption=Performance;
 PLOT R.*(P. Performance); #R. will plot residual for *(P. Performance) [the P. is response estimate from the model, and Performance is actual predictor variable]
PLOT STUDENT.*OBS. / #(STUDENT. will divide residuals by standard errors and *OBS. is what it will be plotted by as number of observations
VREF=3 2 -2 -3 #refrence lines for studentized residuals
VAXIS=-4 TO 4 BY 1 #upper and lower bounds of studnized residual plot 
HAXIS=0 TO 32 BY 1; # left and right bounds of the studentized residual plot 
PLOT RESIDUAL.* NQQ.; # residual by qq plot 
SYMBOL V=DOT;
TITLE "Plots Of Diagnostic Statistics";
RUN;
QUIT;
```

Plot of residuals vs. predicted values of Oxygen_Consumption (dependent variable)

-   randomly scattered about the reference line at 0
-   no apparent trends or patterns
-   check

Plot of residuals vs. observed values of Performance (independent variable)

Since residuals scatter around 0, we can verify the assumption:

-   Have a mean of 0 at each value of the independent variable.
-   Because of no apparent trends or patterns in the residuals, we can verify the assumption:
-   Have the same variance at each value of the independent variable.
-   check

Studentized Residuals vs. actual predictor values given to produce regression line

-   produce studentship residuals vs observation number
-   no unusually large residuals -\> check
-   produce residuals vs normal quantiles
-   straight qq line --\> normal -\> check


### Proc Reg - with fitted model 
don't forget to check the signifgance levels of intercept and coef of regression model
```{r,eval=FALSE}
GOPTIONS RESET=ALL FTEXT='ARIAL/BO' GUNIT=PCT HTEXT=3;
#The PROC REG statement is used when you want to fit a model to the data, you must also use a MODEL statement;
PROC REG DATA=fitness;  
  MODEL Oxygen_Consumption = Performance/ CLB ALPHA=0.01;
#MODEL dependent variable(s)= independent-variables/ options;
#CLB: computes 100(1-a) % confidence limits for the parameter estimates;
#ALPHA= option sets significance value for confidence and prediction intervals and tests;
  PLOT Oxygen_Consumption*Performance;
#The PLOT statement in PROC REG displays scatter plots with y variable on the vertical axis, x variable on the horizontal axis, and the regression line;
  SYMBOL V=DOT H=1.5 CV=RED W=2 CI=BLACK ;
RUN;
QUIT;
```

### Proc Reg - Need Predictions with confidence interval

```{r,eval=FALSE}
proc import datafile="/home/u63989204/Module 7/Module 7 Labs/muscle.txt"
dbms=dlm
out = work.muscle_and_age replace;
getnames=yes;
option validvarname=v7;
run;

proc contents data=work.muscle_and_age;
run;

data muscle;
set work.muscle_and_age;
run;

DATA NEEDEDPREDICTIONS;
INPUT AGE @@;
DATALINES;
66 40
;

RUN;
DATA PREDICT;
SET MUSCLE NEEDEDPREDICTIONS;
RUN;
PROC REG DATA=PREDICT;
MODEL MASS=AGE / P CLM ALPHA=0.02;
RUN;
```

### Proc Reg - compairing goodness of fit for transformed variable linear model 

```{r,eval=FALSE}
data dose_response;
input dose systolic diastolic;
log_dose = LOG(dose);
datalines;
4 180 110
4 190 108
4 178 100
8 170 100
8 180 98
8 168 88
16 160 80
16 172 86
16 170 86
32 140 80
32 130 72
32 128 70
;

PROC REG DATA = dose_response;
    MODEL systolic = log_dose;
    plot systolic*log_dose;
    MODEL diastolic = log_dose;
    plot diastolic*log_dose;
RUN;

PROC REG DATA=dose_response;
   MODEL systolic = log_dose;  #replace with MODEL systolic = log_dose / NOPRINT; if only want the plot
   PLOT RESIDUAL.*log_dose; 
   MODEL diastolic = log_dose;
   PLOT RESIDUAL.*log_dose; 
RUN;
```
in examination of the adjusted r-square, the non transformed predictor variable was better for Systolic blood pressure 
and the natural logarithim LOG() was better for Diastolic blood pressure 


# Module 9 

## base functions 

```{r,eval=FALSE}
my_seq3 <- rep(2, times = 10)   # repeats 2, 10 times
my_seq3
##  [1] 2 2 2 2 2 2 2 2 2 2


my_seq7 <- rep(c(3, 1, 10, 7), each = 3) # repeats each 
                                         # element of the 
                                         # series 3 times
my_seq7
##  [1]  3  3  3  1  1  1 10 10 10  7  7  7


#match - finds the location of the arguments of the first input in the second input
# Define two vectors
x <- c("a", "b", "c", "d")
table <- c("c", "a", "b", "e")

# Match positions of elements of x in table
match(x, table)
# Output: [1] 2 3 1 NA




# Define a vector
x <- c(1, 2, 3, 4)

cumsum(x)
# Output: [1]  1  3  6 10

cumprod(x)
# Output: [1]  1  2  6 24

```



# Module 10 

## reading in data

```{r,eval=FALSE}
setwd("C:/Users/jake pc/Desktop/test_file") #file path 
flowers <- read.table(file = 'flower(1).txt', header = TRUE, sep = "\t", stringsAsFactors = TRUE) #only needs file name
```
additional function arguments 
```{r,eval=FALSE}
dec = "," #if you're in europe 
na.strings = "*" #if they represent an empty element by somehing other than NA
sep = "\t" #tab delimeted 
sep = "," # for csv 
```

if you have to read a fucked up file then just find a package for it on the spot 


## indexing data frames
```{r,eval=FALSE}
flowers[-(1:85), -c(4, 7, 8)]
##    treat nitrogen block weight leafarea
## 86 notip      low     1   6.01     17.6
## 87 notip      low     1   9.93     12.0
## 88 notip      low     1   7.03      7.9
## 89 notip      low     2   9.10     14.5
## 90 notip      low     2   9.05      9.6
## 91 notip      low     2   8.10     10.5
## 92 notip      low     2   7.45     14.1
## 93 notip      low     2   9.19     12.4
## 94 notip      low     2   8.92     11.6
## 95 notip      low     2   8.44     13.5
## 96 notip      low     2  10.60     16.2
```

difference between %in% and == operators
```{r,eval=FALSE}
> x <- c('a','b','c')
> y <- c('c', 'b', 'a')
> x == y
[1] FALSE  TRUE FALSE

> x %in% y
[1] TRUE TRUE TRUE

> x %in% letters
[1] TRUE TRUE TRUE

> letters %in% x
 [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE
 [7] FALSE FALSE FALSE FALSE FALSE FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE
[19] FALSE FALSE FALSE FALSE FALSE FALSE
[25] FALSE FALSE
```

subset function 
```{r}
setwd("C:/Users/jake pc/Desktop/module 10 - tutorials")
flowers <- read.csv("flower(1).csv")

tipplants <- subset(flowers, treat == "tip" & nitrogen == "medium" & block == 2, 
                    select = c("treat", "nitrogen", "leafarea"))
#select to chose which variables of the satisfying rows to extract
tipplants

tip_med_2 <- subset(flowers, treat == "tip" & nitrogen == "medium" & block == 2)
tip_med_2

```


## ordering data frames
the rows of the data frame will be ordered such that both conditions are satisfied 
```{r,eval=FALSE}
block_height_ord <- flowers[order(flowers$block, flowers$height), ]        
block_height_ord
```

same thing but reverse the desired order for one of the variables 
```{r,eval=FALSE}
block_revheight_ord <- flowers[order(flowers$block, -flowers$height), ]        
block_revheight_ord
```

reverse the order of a factor column - now the df has been ordered by least to greatest of height and reverse alphebetical order of nitrogren, mutually satisfied
```{r,eval=FALSE}
block_revheight_ord <- flowers[order(-xtfrm(flowers$nitrogen), flowers$height), ]        
block_revheight_ord
```

## factor - order

this will print the data frame rows ordered by low medium high of nitrogen
```{r,eval=FALSE}
flowers$nitrogen <- factor(flowers$nitrogen, 
                           levels = c("low", "medium", "high"))    
nit_ord <- flowers[order(flowers$nitrogen),]
nit_ord
```


## merging data frames 

if two data frames have at leat one variable in common you can just merge them
the merged data set will only contain observations which have a value for the common variable.
```{r,eval=FALSE}
taxa <- data.frame(GENUS = c("Patella", "Littorina", "Halichondria", "Semibalanus"),
         species = c("vulgata", "littoria", "panacea", "balanoides"),
         family = c("patellidae", "Littorinidae", "Halichondriidae", "Archaeobalanidae"))


zone <- data.frame(genus = c("Laminaria", "Halichondria", "Xanthoria", "Littorina", 
                             "Semibalanus", "Fucus"),
                   species = c("digitata", "panacea", "parietina", "littoria", 
                               "balanoides", "serratus"),
                   zone = c( "v_low", "low", "v_high", "low_mid", "high", "low_mid"))


taxa_zone <- merge(x = taxa, y = zone)
taxa_zone
```



 If we want even the rows without any common variable entry, then we use option 
```{r,eval=FALSE}
taxa_zone <- merge(x = taxa, y = zone, all = TRUE)
taxa_zone
#the missing value will just be NA
```


if we want to merge data frames by a variable but the variable names in each are different then we
```{r,eval=FALSE}
taxa_zone <- merge(x = taxa, y = zone, by.x = "GENUS", by.y = "genus", all = TRUE)
taxa_zone
```

or multiple variable names 
```{r,eval=FALSE}
taxa_zone <- merge(x = taxa, y = zone, by.x = c("species", "GENUS"), 
                    by.y = c("species", "genus"), all = TRUE)
```


### reshaping data frames 

melt() for wide to long df formats 
```{r,eval=FALSE}
library(reshape2)
wide_data <- read.csv(file="wide_format_example.csv",header=TRUE)
wide_data

long_data <- melt(data = wide_data, id.vars = c("StudentID", "Name"),
                   measured.vars = c("Math_Score", "English_Score", "Science_Score"),
                   variable.name = "Subject", value.name = "Scores")
```

dcast() for long to wide formatting
```{r,eval=FALSE}
# StudentID + Name ~ Subject, value.var = "Scores"
#columns which will remain unchanged ~ column_of_categories, value.var = "value of those categories when it was wide"
back_to_wide <- dcast(data = long_data, StudentID + Name ~ Subject, value.var = "Scores")
back_to_wide
```

### table function
will give you the counts of whatever inputted stratification categories , factors and numeric
```{r,eval=FALSE}
flowers <- read.csv(file="flowers.csv",header=TRUE)
table(flowers$nitrogen, flowers$treat)
```

### xtabs - ftable - tapply 
```{r,eval=FALSE}
# the right side of the ~ is all variables we would like to stratify and produce counts for 
xtabs(~ nitrogen + treat + block, data = flowers)
# will take care of data if not already factored 

ftable(xtabs(~ nitrogen + treat + block, data = flowers))

#evaluate the mean height of each category of nitrogen 
tapply(flowers$height, flowers$nitrogen, mean)
#the third argument is any function you would like, first is what it will be applied on, and second is the categories of division of the first variable 

tapply(flowers$height, flowers$nitrogen, sd)

# if there are NA's in the data and want to remove them 
tapply(flowers$height, flowers$nitrogen, summary, na.rm=TRUE)

# you can even pass lists of categories to stratify the variables to be evaluated by the function
tapply(flowers$height, list(flowers$nitrogen,flowers$treat), summary, na.rm=TRUE)
```
### aggregate
```{r,eval=FALSE}
#input variables for function - stratification categories - function to apply 
aggregate(flowers[, 4:7], by = list(nitrogen = flowers$nitrogen, treat = flowers$treat), FUN = mean)

# after formatting the dates column to be only year char you can do the rest of the problem in a single line 
means_by_year <- aggregate(mat[,2:23],by=list(year=mat[,1]),FUN=mean)

# and if we want to apply the previous to a subset we can do this 
aggregate(height ~ nitrogen + treat, FUN = mean, subset = flowers < 7, data = flowers)

aggregate(height ~ nitrogen + treat, FUN = mean, subset = block == "1", data = flowers)

```

# Module 11 

```{r,eval=FALSE}

```












# Module 12


## general form
```{r,eval=FALSE}
ggplot(data = diamonds, aes(x = carat, y = price, color = color)) + 
  geom_point()

# layer one 
ggplot(data = diamonds, aes(x = carat, y = price, color = stratificaion_category))
#data, variables of data, stratify variables by category and plot that by color dimension just as price is plotted by the y dimension

# layer two 
 geom_point() 
# represent these specified variables and representation distinctions as points 

 # you can hard code the color if you want 
   geom_point(color = "blue")
```

other options for aesthetic mapping, (how the values of the data relate to its visual representation)
```{r,eval=FALSE}

  variable =   position (e.g., x and y coordinates)
    color (outside color)
    fill (inside color)
    shape (of points; e.g., circle, triangle)
    linetype (e.g., solid line, dotted line)
    size
    alpha (transparency)


```


simplify the addition of plot layers 
```{r,eval=FALSE}
p1 <- ggplot(mpg, aes(displ, hwy)) +
        geom_point()
p1  +  scale_x_continuous("Engine displacement (L)") + scale_y_continuous("Highway MPG") # all of these options can be included in here

p1 + labs(x = "Engine displacement (L)", y = "Highway MPG") #label axis

p1 + scale_x_continuous(limits = c(2, 6)) # range

p1 + xlim(2, 6) 

p1 + scale_x_continuous(breaks = c(2, 4, 6)) # this will set where the grid lines of the backround are drawn


p1 + scale_x_continuous(breaks = c(2, 4, 6), label = c("two", "four", "six"))
#will label selected breaks with text instead of numbers 
```


## additional layers 

the color dimension is assaigned to the categories of drv
```{r,eval=FALSE}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color=drv)) + 
  geom_point() + geom_smooth(method="lm") + 
  labs(title ="MPG vs Engine size", x = "Engine size", y = "MPG") + 
  
  # allows us to assign that dimension representation manually
  scale_colour_manual(name = "Drive", values = c("lightpink", "darkseagreen", "lightblue"))
```



in this case cty is a continuous variable, so the color assaignment will be likewise continous shades of blue
```{r,eval=FALSE}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color=cty)) + 
  geom_point() 
```


if we don't like the automatic color gradient, we can specify the one desired
```{r,eval=FALSE}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color=cty)) + 
  geom_point() + 
  scale_color_gradient(name = "City MPG", low = "red", high = "blue")
```




## statistical layers

### histograms
#change lengthout of bins or specify a width
```{r,eval=FALSE}
(data(diamonds))
ggplot(data = diamonds, aes(x = carat)) + geom_histogram(bins=100)
#or 
#geom_histogram(binwidth=0.001) 
```

### histogram of density
```{r,eval=FALSE}
# Create histogram with density
# the variable `density` is created by stat_bin()
ggplot(diamonds, aes(carat)) + 
  geom_histogram(aes(y = ..density..), binwidth = 0.1)
```

## bar plots 
```{r,eval=FALSE}
s <- ggplot(mpg, aes(fl, fill = drv))
#fl is x axis variables, fill = drv means to stratify the color of sections of the bar plot by categories subset to the fl category.
s + geom_bar()
#create a bar plot with this, frequency 

# Stack elements on top of one another
s + geom_bar(position = "stack") 
#does the same thing 

# Arrange elements side by side
s + geom_bar(position = "dodge")
#instead of the categories of fl being within one bar, they're just next to each other now 


# Stack elements on top of one another,normalize height
s + geom_bar(position = "fill")
# all bars will be the same height, the categories will be stacked to demonstraight the distribution of drv categories within fl categories 
```



## faceting

```{r,eval=FALSE}
ggplot(data = diamonds, aes(x = carat)) + 
  geom_histogram(bins=30) + 
  facet_grid(rows = vars(color))
#plot a new row for each different color of carot 

#or columns 

ggplot(data = diamonds, aes(x = carat)) + 
  geom_histogram(bins=30) + 
  facet_grid(cols = vars(color))
```


## grouping


```{r,eval=FALSE}
base_plot <- ggplot(Oxboys, aes(age, height, group = Subject)) + geom_line() 

base_plot + geom_smooth() #not specifying which group

base_plot + geom_smooth(group=1) #specify which group

base_plot + facet_wrap(vars(Subject)) # give each group (subject) their own facet

```


## themes 

```{r,eval=FALSE}
library(ggplot2)
base <- ggplot(mpg, aes(cty, hwy, color = factor(cyl))) +
  geom_jitter() + 
  geom_abline(color = "grey50", linewidth = 2)
base


labelled <- base +
  labs(x = "City mileage/gallon",
       y = "Highway mileage/gallon",
       color = "Cylinders",
       title = "Highway and city mileage are highly correlated") +
       scale_color_brewer(type = "seq", palette = "Spectral")
labelled


styled <- labelled +
  theme_bw() + 
  theme(plot.title = element_text(face = "bold", size = 12),
    legend.background = element_rect(fill = "white", linewidth = 4, color = "white"),
    legend.justification = c(0, 1),
    legend.position = c(0, 1),
    axis.ticks = element_line(color = "grey70", linewidth = 0.2),
    panel.grid.major = element_line(color = "grey70", linewidth = 0.2),
    panel.grid.minor = element_blank())
styled
```

## themes list 

```{r,eval=FALSE}
theme_grey(): the signature ggplot2 theme with a light grey background and white gridlines.
theme_bw(): a variation on theme_grey() that uses a white background and thin grey gridlines.
theme_linedraw(): a theme with only black lines of various widths on white backgrounds, reminiscent of a line drawing.
theme_light(): similar to theme_linedraw() but with light grey lines and axes, to direct more attention towards the data.
theme_dark(): the dark cousin of theme_light(), with similar line sizes but a dark background. Useful to make thin colored lines pop out.
theme_minimal(): a minimalistic theme with no background annotations.
theme_classic(): a classic-looking theme, with x and y-axis lines and no gridlines.
theme_void(): a completely empty theme.
```

## modifying theme components 

### element text
```{r,eval=FALSE}
base_t <- base + labs(title = "This is a ggplot") + xlab(NULL) + ylab(NULL)
base_t + theme(plot.title = element_text(size = 16))

base_t + theme(plot.title = element_text(face = "bold", color = "red"))

base_t + theme(plot.title = element_text(hjust = 1))

# The margins here look asymmetric because there are also plot margins
#input arguments of margin is amount of space in points to separate the text from whatever 
#margin(t=top,r=right,b=bottom,l=left)
base_t + theme(plot.title = element_text(margin = margin()))

base_t + theme(plot.title = element_text(margin = margin(t=10,b=10)))
```

### element line
element_line() draws lines parameterized by color, size, and linetype:
```{r,eval=FALSE}
base <- base + labs(title = "This is a ggplot") + xlab(NULL) + ylab(NULL)

#make the backround grid major lines black
base + theme(panel.grid.major = element_line(color = "black"))

#change the thickness of the backround grid lines 
base + theme(panel.grid.major = element_line(linewidth = 2))

#make the major grin lines dotted 
base + theme(panel.grid.major = element_line(linetype = "dotted"))

```

### element rect
element_rect() draws rectangles, mostly used for backgrounds, parameterized by fill color and border color, size, and linetype.
```{r,eval=FALSE}
base + theme(plot.background = element_rect(fill = "grey80", color = NA))

base + theme(plot.background = element_rect(color = "red", linewidth = 2))

base + theme(panel.background = element_rect(fill = "linen"))
```

### element blank 

remove elements 
```{r,eval=FALSE}
last_plot() + theme(panel.grid.minor = element_blank())
#remove minor grid marks 
```

remove major grid marks
```{r,eval=FALSE}
last_plot() + theme(panel.grid.major = element_blank())
ggsave("test.pdf")
```

remove the backround 
```{r,eval=FALSE}
last_plot() + theme(panel.background = element_blank())
```


ggsave
```{r,eval=FALSE}
ggsave("test.pdf") #call underneath the plot command to save the last one 
```


check and submit homework 12 
